{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16b34d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "           building    y              ts  capacity                      ds  \\\n",
      "0  Mensa Geb√§ude U8  0.0  18.08.24 19:54     500.0 2024-08-18 19:54:38.791   \n",
      "\n",
      "        city  \n",
      "0  Heilbronn  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "\n",
    "conn = hopsworks.connection()\n",
    "HEILBONN_API_KEY = conn.get_secrets_api().get_secret(\"HEILBONN_API_KEY\").value\n",
    "    \n",
    "# Define the API URL and API key\n",
    "url = \"https://34.149.159.161.nip.io/bildungscampus/iotplatform/mensaoccupancy/v1/authGroup/mensa_occupancy_devices/entityId?page=0\"\n",
    "\n",
    "# Set up headers with API key\n",
    "headers = {\n",
    "    'x-apikey': HEILBONN_API_KEY\n",
    "}\n",
    "\n",
    "# Send GET request to the API\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    location_names = []\n",
    "    occupancies = []\n",
    "    occupancy_ts = []\n",
    "    capacities = []\n",
    "\n",
    "    # Extract the necessary fields from the JSON response\n",
    "    for entity in data['entities']:\n",
    "        location_names.append(entity['SERVER_ATTRIBUTE']['locationName']['value'])\n",
    "        occupancies.append(entity['TIME_SERIES']['occupancy']['value'])\n",
    "        occupancy_ts.append(entity['TIME_SERIES']['occupancy']['ts'])\n",
    "        capacities.append(entity['TIME_SERIES']['capacity']['value'])\n",
    "\n",
    "##### We will not use these attributes in the simple example AI system\n",
    "#         occupancy_relatives.append(entity['TIME_SERIES']['occupancyRelative']['value'])\n",
    "#         occupancy_relative_ts.append(entity['TIME_SERIES']['occupancyRelative']['ts'])\n",
    "#         location_ts.append(entity['SERVER_ATTRIBUTE']['locationName']['ts'])\n",
    "#         out_counts.append(entity['TIME_SERIES']['outCount']['value'])\n",
    "#         out_count_ts.append(entity['TIME_SERIES']['outCount']['ts'])\n",
    "#         in_counts.append(entity['TIME_SERIES']['inCount']['value'])\n",
    "#         in_count_ts.append(entity['TIME_SERIES']['inCount']['ts'])        \n",
    "#         capacity_ts.append(entity['TIME_SERIES']['capacity']['ts'])\n",
    "\n",
    "    # Create a DataFrame from the lists\n",
    "    df = pd.DataFrame({\n",
    "        'building': location_names,\n",
    "        'y': occupancies,\n",
    "        'ts': occupancy_ts,\n",
    "        'capacity': capacities,\n",
    "    })\n",
    "\n",
    "    # Convert UNIX timestamps to pandas datetime\n",
    "    df['ds'] = pd.to_datetime(df['ts'], unit='ms')\n",
    "    # Convert pandas datetime to string\n",
    "    df['ts'] = df['ds'].dt.strftime('%d.%m.%y %H:%M')\n",
    "    # Convert str to double (errors become NaN)\n",
    "    df['y'] = df['y'].astype(float)\n",
    "    df['capacity'] = df['capacity'].astype(float)\n",
    "    df['city'] = \"Heilbronn\"\n",
    "    print(df)\n",
    "else:\n",
    "    print(f\"Failed to retrieve data: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddb53f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/16503\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "fs = hopsworks.login().get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b166a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = fs.get_feature_group(name=\"mensa\", version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7c81793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288ace3f6e0b43c4bc1a1b9e98d4f5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: mensa_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://snurran.hops.works/p/16503/jobs/named/mensa_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7f0bc7791660>, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg.insert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59217e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
